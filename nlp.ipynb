{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8AOlLMV/ER/fxeZox63pv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemanth160425/nlpbasics/blob/main/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOXJx01iiEL5",
        "outputId": "3f673124-e569-4218-ef88-157532c7641e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# punkt is a tokenizer for many languages ."
      ],
      "metadata": {
        "id": "x6ZxZWwJsIr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\"\" hello welcome to google colab . today our topic is about tokenization . this cover most of the topics\"\"\""
      ],
      "metadata": {
        "id": "OCEs8FlCrW9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "CY97JXVYrp7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=sent_tokenize(corpus)"
      ],
      "metadata": {
        "id": "fWCl5Efbrp9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in doc:\n",
        "  print(word_tokenize(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwsFIK9zsISp",
        "outputId": "d244cc55-f763-4538-8d79-5dbd645cb90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'welcome', 'to', 'google', 'colab', '.']\n",
            "['today', 'our', 'topic', 'is', 'about', 'tokenization', '.']\n",
            "['this', 'cover', 'most', 'of', 'the', 'topics']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpLcOehDrqA5",
        "outputId": "01a9e552-a166-4e09-f8cc-e136d3cd1b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello',\n",
              " 'welcome',\n",
              " 'to',\n",
              " 'google',\n",
              " 'colab',\n",
              " '.',\n",
              " 'today',\n",
              " 'our',\n",
              " 'topic',\n",
              " 'is',\n",
              " 'about',\n",
              " 'tokenization',\n",
              " '.',\n",
              " 'this',\n",
              " 'cover',\n",
              " 'most',\n",
              " 'of',\n",
              " 'the',\n",
              " 'topics']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "t=TreebankWordTokenizer()"
      ],
      "metadata": {
        "id": "DVhKcrtEtNpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdLK0CdrtWYH",
        "outputId": "431332e7-e332-4450-d7f7-1ddac4e1ee96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello',\n",
              " 'welcome',\n",
              " 'to',\n",
              " 'google',\n",
              " 'colab',\n",
              " '.',\n",
              " 'today',\n",
              " 'our',\n",
              " 'topic',\n",
              " 'is',\n",
              " 'about',\n",
              " 'tokenization',\n",
              " '.',\n",
              " 'this',\n",
              " 'cover',\n",
              " 'most',\n",
              " 'of',\n",
              " 'the',\n",
              " 'topics']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Stemming\n",
        "\n",
        "# Definition: Stemming is the process of reducing a word to its base or root form by removing suffixes or prefixes.\n",
        "\n",
        "# Purpose: It helps in reducing different forms of a word to a common base, improving the performance of text analysis tasks like search, classification, and clustering.\n",
        "\n",
        "# Applications: Commonly used in Natural Language Processing (NLP), information retrieval, and search engines to match words with the same root despite having different suffixes (e.g., \"running\" becomes \"run\").\n",
        "\n",
        "# Algorithm Types: Popular stemming algorithms include the Porter Stemmer, Snowball Stemmer, and Lancaster Stemmer.\n",
        "\n",
        "# Porter Stemmer: A widely used and influential algorithm that removes common suffixes using a series of rules, but it can be somewhat conservative.\n",
        "\n",
        "# Lancaster Stemmer: An aggressive stemmer that may over-stem words, making them too general (e.g., \"maximum\" becomes \"max\").\n",
        "\n",
        "# Efficiency: Stemming reduces the number of unique terms in a text corpus, thus saving storage space and computational resources.\n",
        "\n",
        "# Overstemming and Understemming: Overstemming leads to too many words being reduced to the same root, while understemming leaves too many variations of the same word.\n",
        "\n",
        "# Difference from Lemmatization: Unlike stemming, lemmatization uses vocabulary and morphological analysis of words to return the dictionary form (lemma) rather than just removing prefixes or suffixes.\n",
        "\n",
        "# Limitations: Stemming may not always produce real words (e.g., \"fishing\" becomes \"fish,\" but \"happiness\" may become \"happi\"), which can lead to confusion in some applications."
      ],
      "metadata": {
        "id": "AOjEnHKutWaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "t=['eat','eats','eating']\n",
        "for k in t:\n",
        "  print(PorterStemmer().stem(k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71c0K87ltWbw",
        "outputId": "835ab1ac-923c-45a8-c76d-869c29dce225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eat\n",
            "eat\n",
            "eat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# diffretn types of stem are porter , snowball , lancaster , etc"
      ],
      "metadata": {
        "id": "eH8XTsZ5tWdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Stemming\n",
        "\n",
        "# Definition: Lemmatization is the process of reducing a word to its base or dictionary form, known as the \"lemma,\" based on its meaning and context.\n",
        "\n",
        "# Purpose: It helps in normalizing words by mapping inflected forms to a common base form, improving the accuracy of text analysis tasks like search, sentiment analysis, and language translation.\n",
        "\n",
        "# Applications: Used in Natural Language Processing (NLP) tasks such as tokenization, text classification, information retrieval, and search engines to process and analyze textual data.\n",
        "\n",
        "# Context-Aware: Unlike stemming, lemmatization considers the part of speech (POS) and context to determine the correct base form (e.g., \"better\" is lemmatized to \"good\" if used as an adjective).\n",
        "\n",
        "# Uses a Dictionary: Lemmatization relies on a morphological dictionary or vocabulary to identify the correct lemma of a word (e.g., \"better\" is linked to \"good\").\n",
        "\n",
        "# POS Tagging: To lemmatize correctly, words need to be tagged with their part of speech, as this influences the base form (e.g., \"running\" as a verb is reduced to \"run,\" but as a noun remains \"running\").\n",
        "\n",
        "# More Accurate than Stemming: Lemmatization is more precise because it returns actual words in their base form, whereas stemming may result in incorrect or incomplete words.\n",
        "\n",
        "# Slower than Stemming: Due to its complexity and the need for POS tagging and dictionary lookup, lemmatization is typically slower and more resource-intensive than stemming.\n",
        "\n",
        "# Difference from Stemming: Stemming only removes suffixes and prefixes without considering context, while lemmatization involves deeper linguistic analysis to ensure the base word is meaningful.\n",
        "\n",
        "# Popular Libraries: Lemmatization tools are available in libraries like NLTK (Natural Language Toolkit) and spaCy, commonly used for NLP tasks in Python."
      ],
      "metadata": {
        "id": "v4N5WPzzzfIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "WordNetLemmatizer().lemmatize('going')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "dneKUs_TzfK_",
        "outputId": "0b46da07-239f-46f6-ed1f-3a1708684d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'going'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WordNetLemmatizer().lemmatize('going',pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "82ZNr5-QzfNM",
        "outputId": "f6c56e29-2c9a-450e-b406-edb7eab5fba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyFSjyP1zfQT",
        "outputId": "3fcff1c1-6b47-4ea5-861c-e92368c5ee49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "para='''Natural language processing (NLP) is a branch of artif\n",
        "icial intelligence that focuses on the interaction between computers a\n",
        "nd humans through language. It involves enabling machines to understand, interpret,\n",
        " and generate human language in a way that is both meaningful and useful. Applications\n",
        " of NLP include language translation, sentiment analysis, and chatbot development, among\n",
        " others. With advancements in deep learning and machine learning algorithms, NLP has seen\n",
        " tremendous growth in recent years, enabling more sophisticat\n",
        "ed models that can perform tasks such as text classification, named entity recognition, and question-answering with high accuracy.'''"
      ],
      "metadata": {
        "id": "TPRpIRN9zfSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=nltk.sent_tokenize(para)"
      ],
      "metadata": {
        "id": "UW_pN-qCzfUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Example sentences\n",
        "sentences = [\"Natural language processing is fascinating.\", \"It involves both linguistics and computer science.\"]\n",
        "\n",
        "# Ensure stopwords are downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize the PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "# Loop through each sentence\n",
        "for i in range(len(sentences)):\n",
        "    # Tokenize the sentence\n",
        "    words = word_tokenize(sentences[i])\n",
        "\n",
        "    # Apply stemming and remove stopwords\n",
        "    words = [ps.stem(word) for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # Join the words back into a sentence\n",
        "    sentences[i] = ' '.join(words)\n",
        "\n",
        "# Output the processed sentences\n",
        "print(sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM6en9NZw52G",
        "outputId": "75bfccf7-5836-4393-fca6-c3df30cb961a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natur languag process fascin .', 'involv linguist comput scienc .']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yn_9_8BJV4fi",
        "outputId": "65dd9c7c-f241-4c41-d869-dd4eae61fea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'natur languag process fascin .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Example sentences\n",
        "sentences = [\"Natural language processing is fascinating.\", \"It involves both linguistics and computer science.\"]\n",
        "\n",
        "# Ensure necessary NLTK data is downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Initialize the WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Loop through each sentence\n",
        "for i in range(len(sentences)):\n",
        "    # Tokenize the sentence\n",
        "    words = word_tokenize(sentences[i])\n",
        "\n",
        "    # Set of stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Apply lemmatization and remove stopwords\n",
        "    words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # Join the words back into a sentence\n",
        "    sentences[i] = ' '.join(words)\n",
        "\n",
        "# Output the processed sentences\n",
        "print(sentences)\n"
      ],
      "metadata": {
        "id": "OjQWp0MYw54S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1dea56b-780d-4db8-bcff-52f8e2129c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural language processing fascinating .', 'involves linguistics computer science .']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0]"
      ],
      "metadata": {
        "id": "ZgQhiXDDw56Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "445f7423-2895-4d6e-91e8-bc2f124713f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'natural language processing fascinating .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VNfCcQaaHHH",
        "outputId": "93b39bb4-d1aa-413d-be4b-bf0434e46e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5dRdJSacQrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "sentences = [\"Natural language processing is fascinating.\", \"It involves both linguistics and computer science.\"]\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "    # Tokenize the sentence\n",
        "    words = word_tokenize(sentences[i])\n",
        "\n",
        "    # Set of stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "    words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    poss_tag=nltk.pos_tag(words)\n",
        "    print(poss_tag)\n"
      ],
      "metadata": {
        "id": "XjOIS8kmw58Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279e75a0-d595-43db-ee4a-977ebd41a4ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('fascinating', 'NN'), ('.', '.')]\n",
            "[('involves', 'NNS'), ('linguistics', 'NNS'), ('computer', 'NN'), ('science', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhjgLACzeMfA",
        "outputId": "a6709642-ebca-4675-b143-8eb2c071f892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# name entity recogniton\n",
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "s = \"Natural language processing is fascinating. It involves both linguistics and computer science.\"\n",
        "\n",
        "t=nltk.word_tokenize(s)\n",
        "\n",
        "poss_tag=nltk.pos_tag(t)\n",
        "nltk.ne_chunk(poss_tag).draw\n"
      ],
      "metadata": {
        "id": "dYYCYrEqw59t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "f0b7bf56-1ae4-4523-fcd7-357513cfa8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Tree.draw of Tree('S', [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('is', 'VBZ'), ('fascinating', 'VBG'), ('.', '.'), ('It', 'PRP'), ('involves', 'VBZ'), ('both', 'DT'), ('linguistics', 'NNS'), ('and', 'CC'), ('computer', 'NN'), ('science', 'NN'), ('.', '.')])>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.tree.tree.Tree.draw</b><br/>def draw()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/nltk/tree/tree.py</a>Open a new window containing a graphical diagram of this tree.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 755);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "PchhnsMrevZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f4ac287-def7-4b5c-b265-29f16bab7822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "NE4MVtAwevca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d545ef49-5bad-4f82-b34d-8a7d1e896447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##tensorflow >2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "metadata": {
        "id": "4CMCjY5mevgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### sentences\n",
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good']"
      ],
      "metadata": {
        "id": "YbOXTSYaQA6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sr7KdCTQA9D",
        "outputId": "a94a8de0-464c-451f-813d-34bbc5a6b3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size=500\n",
        "onehot_repr=[one_hot(words,voc_size)for words in sent]\n",
        "print(onehot_repr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWPzlTHLQBAq",
        "outputId": "228aad5a-3584-4560-9804-2a6db86c7290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[241, 382, 176, 80], [241, 382, 176, 294], [241, 153, 176, 305], [499, 152, 41, 117, 280], [499, 152, 41, 117, 437], [483, 241, 389, 176, 80], [166, 212, 109, 117]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gfGaz3KSQL9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## pre padding\n",
        "sent_length=8\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVEFn-PpQL_p",
        "outputId": "ba6b50ce-186c-47a0-9337-c3dc26d80ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0 241 382 176  80]\n",
            " [  0   0   0   0 241 382 176 294]\n",
            " [  0   0   0   0 241 153 176 305]\n",
            " [  0   0   0 499 152  41 117 280]\n",
            " [  0   0   0 499 152  41 117 437]\n",
            " [  0   0   0 483 241 389 176  80]\n",
            " [  0   0   0   0 166 212 109 117]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 10 feature dimesnions\n",
        "dim=10"
      ],
      "metadata": {
        "id": "_bqTsOZQQMFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
        "model.compile('adam','mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "sURGAYAeQMHY",
        "outputId": "a9289e42-7a95-4989-962a-810cbe902167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##'the glass of milk',\n",
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imDdGiWcQMLf",
        "outputId": "232aa9c5-8f21-414b-8194-f902fd384a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0, 241, 382, 176,  80], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(embedded_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYAiquKNQMOE",
        "outputId": "3acabc17-9683-47e5-9eef-638a3612d7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.048448  ,  0.00498738,  0.00416286,  0.03011911,  0.03405705,\n",
              "         0.00312258,  0.01926457, -0.00547083, -0.01265547,  0.00722307],\n",
              "       [ 0.048448  ,  0.00498738,  0.00416286,  0.03011911,  0.03405705,\n",
              "         0.00312258,  0.01926457, -0.00547083, -0.01265547,  0.00722307],\n",
              "       [ 0.048448  ,  0.00498738,  0.00416286,  0.03011911,  0.03405705,\n",
              "         0.00312258,  0.01926457, -0.00547083, -0.01265547,  0.00722307],\n",
              "       [ 0.048448  ,  0.00498738,  0.00416286,  0.03011911,  0.03405705,\n",
              "         0.00312258,  0.01926457, -0.00547083, -0.01265547,  0.00722307],\n",
              "       [-0.01878327,  0.00802612, -0.01391339, -0.00739123,  0.02204578,\n",
              "         0.04552731,  0.01223477, -0.0288033 , -0.01654165, -0.01644988],\n",
              "       [-0.0236474 ,  0.02278558, -0.0269809 ,  0.0411031 ,  0.03689874,\n",
              "        -0.03080672, -0.03566187,  0.02934027, -0.00027283,  0.00322007],\n",
              "       [-0.02831816, -0.03966511,  0.03793517,  0.02296552,  0.02983199,\n",
              "         0.01588723,  0.02574766,  0.02331244,  0.02776916,  0.01219375],\n",
              "       [-0.00400966, -0.0248556 , -0.04803424,  0.04278814, -0.04223659,\n",
              "        -0.02675756, -0.04197938,  0.04024068, -0.04445194,  0.04200153]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drn2vwAfQrIJ",
        "outputId": "df6cd8c9-9c81-42d0-a3ab-47aef050e697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0, 241, 382, 176,  80], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}